{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a42cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los datos\n",
    "df = pd.read_csv('../results/datos_normalizados.csv', sep=',')\n",
    "df_cluster = pd.read_csv('../results/paises_agrupados_por_completitud.csv', sep=',')\n",
    "\n",
    "# Combinar usando nombres distintos de columna\n",
    "df = df.merge(df_cluster[['Pa√≠s', 'Cluster']], left_on='√Årea', right_on='Pa√≠s', how='left')\n",
    "\n",
    "# Eliminar la columna duplicada 'Pa√≠s' si ya no la necesitas\n",
    "df = df.drop(columns='Pa√≠s')\n",
    "\n",
    "# Verificar resultado\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50242a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Cluster'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17392e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asumimos que df tiene columnas: ['√Årea', 'Producto', 'Elemento', 'A√±o', 'Valor']\n",
    "\n",
    "# --- 1Ô∏è‚É£ Obtener el conjunto de elementos por producto ---\n",
    "elements_per_product = (\n",
    "    df.groupby(\"Producto\")[\"Elemento\"]\n",
    "    .unique()\n",
    "    .apply(set)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# --- 2Ô∏è‚É£ Verificar si todos los productos tienen el mismo conjunto de elementos ---\n",
    "all_elements = set.union(*elements_per_product.values())  # conjunto total\n",
    "incomplete = {\n",
    "    prod: all_elements - elems\n",
    "    for prod, elems in elements_per_product.items()\n",
    "    if elems != all_elements\n",
    "}\n",
    "\n",
    "print(\"Elementos totales encontrados:\", all_elements)\n",
    "print(f\"Total de productos analizados: {len(elements_per_product)}\")\n",
    "print(f\"Productos con elementos incompletos: {len(incomplete)}\")\n",
    "\n",
    "# --- 3Ô∏è‚É£ Mostrar detalle de productos incompletos ---\n",
    "if incomplete:\n",
    "    print(\"\\n--- Productos con elementos faltantes ---\")\n",
    "    for prod, missing in incomplete.items():\n",
    "        present = elements_per_product[prod]\n",
    "        print(f\"Producto: {prod}\")\n",
    "        print(f\"  ‚Üí Elementos presentes: {sorted(list(present))}\")\n",
    "        print(f\"  ‚Üí Elementos faltantes: {sorted(list(missing))}\\n\")\n",
    "\n",
    "# --- 4Ô∏è‚É£ (opcional) Resumen tabular de completitud ---\n",
    "summary = []\n",
    "for prod, elems in elements_per_product.items():\n",
    "    summary.append({\n",
    "        \"Producto\": prod,\n",
    "        \"Elementos presentes\": len(elems),\n",
    "        \"Elementos esperados\": len(all_elements),\n",
    "        \"Porcentaje completo\": round(100 * len(elems) / len(all_elements), 2)\n",
    "    })\n",
    "df_summary = pd.DataFrame(summary).sort_values(\"Porcentaje completo\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4cefcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nResumen de completitud por producto:\")\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445a2f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1Ô∏è‚É£ Verificar si hay duplicados ---\n",
    "duplicates = df.duplicated(subset=[\"√Årea\", \"Producto\", \"Elemento\", \"A√±o\"], keep=False)\n",
    "if duplicates.any():\n",
    "    print(f\"‚ö†Ô∏è Se encontraron {duplicates.sum()} filas duplicadas. Se promediar√°n los valores repetidos.\")\n",
    "    # Agrupamos y promediamos los valores repetidos\n",
    "    df = (\n",
    "        df.groupby([\"√Årea\", \"Producto\", \"Elemento\", \"A√±o\"], as_index=False)\n",
    "          .agg({\"Valor\": \"mean\"})\n",
    "    )\n",
    "else:\n",
    "    print(\"‚úÖ No hay duplicados exactos por combinaci√≥n de claves.\")\n",
    "\n",
    "# --- 2Ô∏è‚É£ Crear el √≠ndice completo ---\n",
    "all_areas = df[\"√Årea\"].unique()\n",
    "all_products = df[\"Producto\"].unique()\n",
    "all_elements = df[\"Elemento\"].unique()\n",
    "all_years = sorted(df[\"A√±o\"].unique())\n",
    "\n",
    "full_index = pd.MultiIndex.from_product(\n",
    "    [all_areas, all_products, all_elements, all_years],\n",
    "    names=[\"√Årea\", \"Producto\", \"Elemento\", \"A√±o\"]\n",
    ")\n",
    "\n",
    "# --- 3Ô∏è‚É£ Reindexar el dataframe ---\n",
    "df_full = (\n",
    "    df.set_index([\"√Årea\", \"Producto\", \"Elemento\", \"A√±o\"])\n",
    "      .reindex(full_index)\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# --- 4Ô∏è‚É£ Detectar huecos ---\n",
    "missing_mask = df_full[\"Valor\"].isna()\n",
    "missing = df_full[missing_mask]\n",
    "\n",
    "print(f\"üîç Total de combinaciones posibles: {len(df_full):,}\")\n",
    "print(f\"‚ùå Huecos encontrados: {missing_mask.sum():,}\")\n",
    "print(f\"‚úÖ Datos completos: {len(df_full) - missing_mask.sum():,}\")\n",
    "\n",
    "# --- 5Ô∏è‚É£ Mostrar resumen por pa√≠s ---\n",
    "resumen = (\n",
    "    missing.groupby(\"√Årea\")\n",
    "    .size()\n",
    "    .reset_index(name=\"Huecos\")\n",
    "    .sort_values(\"Huecos\", ascending=False)\n",
    ")\n",
    "print(\"\\n--- Pa√≠ses con datos incompletos ---\")\n",
    "print(resumen.head(10))\n",
    "\n",
    "# --- 6Ô∏è‚É£ (Opcional) Exportar para inspecci√≥n manual ---\n",
    "missing.to_csv(\"../results/missing_combinations.csv\", index=False)\n",
    "print(\"\\nüíæ Archivo 'missing_combinations.csv' guardado con los huecos detectados.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850851e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_1990 = {\n",
    "    # --- categor√≠as iguales ---\n",
    "    'Residuos agr√≠colas': 'Residuos agr√≠colas',\n",
    "    'Cultivo del arroz': 'Cultivo del arroz',\n",
    "    'Quemado de residuos agr√≠colas': 'Quemado de residuos agr√≠colas',\n",
    "    'Fermentaci√≥n ent√©rica': 'Fermentaci√≥n ent√©rica',\n",
    "    'Gesti√≥n del esti√©rcol': 'Gesti√≥n del esti√©rcol',\n",
    "    'Esti√©rcol depositado en las pasturas': 'Esti√©rcol depositado en las pasturas',\n",
    "    'Esti√©rcol aplicado a los suelos': 'Esti√©rcol aplicado a los suelos',\n",
    "    'Fertilizantes sint√©ticos': 'Fertilizantes sint√©ticos',\n",
    "    'Energ√≠a': 'Energ√≠a',\n",
    "    'IPPU': 'IPPU',\n",
    "    'Desechos': 'Desechos',\n",
    "    'Otro': 'Otro',\n",
    "    'Emisiones derivadas de los cultivos': 'Emisiones derivadas de los cultivos',\n",
    "    'Emissiones derivadas del sector ganadero': 'Emissiones derivadas del sector ganadero',\n",
    "    'IPCC Agricultura': 'IPCC Agricultura',\n",
    "    'Suelos agr√≠colas': 'Suelos agr√≠colas',\n",
    "\n",
    "    # --- nuevas categor√≠as agrupadas ---\n",
    "    # Suelos, uso de la tierra, y drenaje\n",
    "    'Suelos org√°nicos drenados': 'Suelos agr√≠colas',\n",
    "    'Suelos org√°nicos drenados (CO2)': 'Suelos agr√≠colas',\n",
    "    'Suelos org√°nicos drenados (N2O)': 'Suelos agr√≠colas',\n",
    "    'Tierras forestales': 'Suelos agr√≠colas',\n",
    "    'Conversi√≥n neta de bosques': 'Suelos agr√≠colas',\n",
    "    'Cambios de uso de la tierra': 'Suelos agr√≠colas',\n",
    "    'Emisiones en tierras agr√≠colas': 'Suelos agr√≠colas',\n",
    "    'LULUCF': 'Suelos agr√≠colas',\n",
    "    'AFOLU': 'Suelos agr√≠colas',\n",
    "    'Emisiones totales incluyendo LULUCF': 'Suelos agr√≠colas',\n",
    "    'Emisiones totales excluyendo LULUCF': 'Suelos agr√≠colas',\n",
    "\n",
    "    # Incendios\n",
    "    'Incendios de sabana': 'Residuos agr√≠colas',\n",
    "    'Incendios en suelos de turba': 'Residuos agr√≠colas',\n",
    "    'Incendios forestales': 'Residuos agr√≠colas',\n",
    "    'Incendios en los bosques tropicales h√∫medos': 'Residuos agr√≠colas',\n",
    "\n",
    "    # Energ√≠a dentro de la finca\n",
    "    'On-farm energy use': 'Energ√≠a',\n",
    "    'Tanques de combustible internacional': 'Energ√≠a',\n",
    "\n",
    "    # Fabricaci√≥n y procesamiento industrial\n",
    "    'Fabricaci√≥n de fertilizantes': 'IPPU',\n",
    "    'Fabricaci√≥n de pesticidas': 'IPPU',\n",
    "    'Envasado alimentario': 'IPPU',\n",
    "    'Transformaci√≥n\\xa0de alimentos': 'IPPU',\n",
    "\n",
    "    # Sistemas agroalimentarios y comercio\n",
    "    'Sistemas agroalimentarios': 'Otro',\n",
    "    'Farm gate': 'Otro',\n",
    "    'Pre y\\xa0post-producci√≥n': 'Otro',\n",
    "    'Venta de alimentos': 'Otro',\n",
    "    'Consumo\\xa0de alimentos en los hogares': 'Otro',\n",
    "\n",
    "    # Residuos de sistemas alimentarios\n",
    "    'Eliminaci√≥n de desechos de sistemas agroalimentarios': 'Desechos',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5641ef63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Producto'] = df['Producto'].replace(map_1990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bcef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Producto\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f3de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\n",
    "    \"√Årea\",\n",
    "    \"Producto\",\n",
    "    \"Elemento\",\n",
    "    \"A√±o\",\n",
    "    \"Valor\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e242c2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"A√±o\", \"Valor\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a41db74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapear cada categor√≠a a un √≠ndice\n",
    "area_to_idx = {area: i for i, area in enumerate(df[\"√Årea\"].unique())}\n",
    "prod_to_idx = {prod: i for i, prod in enumerate(df[\"Producto\"].unique())}\n",
    "elem_to_idx = {elem: i for i, elem in enumerate(df[\"Elemento\"].unique())}\n",
    "year_to_idx = {year: i for i, year in enumerate(sorted(df[\"A√±o\"].unique()))}\n",
    "\n",
    "# Agregar las columnas indexadas al DataFrame\n",
    "df[\"area_idx\"] = df[\"√Årea\"].map(area_to_idx)\n",
    "df[\"prod_idx\"] = df[\"Producto\"].map(prod_to_idx)\n",
    "df[\"elem_idx\"] = df[\"Elemento\"].map(elem_to_idx)\n",
    "df[\"year_idx\"] = df[\"A√±o\"].map(year_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4ff1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "num_areas = len(area_to_idx)\n",
    "num_prods = len(prod_to_idx)\n",
    "num_elems = len(elem_to_idx)\n",
    "num_years = len(year_to_idx)\n",
    "\n",
    "# Inicializamos el tensor con NaN (o ceros si prefer√≠s)\n",
    "tensor = torch.full(\n",
    "    (num_areas, num_prods, num_elems, num_years),\n",
    "    float('nan')\n",
    ")\n",
    "\n",
    "# Rellenamos con los valores existentes\n",
    "for _, row in df.iterrows():\n",
    "    a, p, e, y = row[\"area_idx\"], row[\"prod_idx\"], row[\"elem_idx\"], row[\"year_idx\"]\n",
    "    tensor[a, p, e, y] = row[\"Valor\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd56bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos la media y desviaci√≥n ignorando NaN de forma manual\n",
    "mask = ~torch.isnan(tensor)\n",
    "mean_val = torch.sum(tensor[mask]) / mask.sum()\n",
    "std_val = torch.sqrt(torch.sum(((tensor[mask] - mean_val) ** 2)) / mask.sum())\n",
    "\n",
    "# AGREGAMOS EPSILON PARA EVITAR DIVISI√ìN POR CERO\n",
    "epsilon = 1e-8\n",
    "std_val = std_val + epsilon\n",
    "\n",
    "print(f\"Media: {mean_val.item():.4f}\")\n",
    "print(f\"Desviaci√≥n est√°ndar: {std_val.item():.4f}\")\n",
    "\n",
    "tensor_norm = (tensor - mean_val) / std_val\n",
    "\n",
    "# Verificar que no hay NaN o Inf despu√©s de normalizar\n",
    "print(f\"NaN despu√©s de normalizaci√≥n: {torch.isnan(tensor_norm).sum().item()}\")\n",
    "print(f\"Inf despu√©s de normalizaci√≥n: {torch.isinf(tensor_norm).sum().item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321bf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_secuencias(tensor, window=5):\n",
    "    \"\"\"\n",
    "    Crea pares (input_seq, target) para entrenamiento temporal.\n",
    "    Cada secuencia tiene longitud 'window' y el target es el siguiente a√±o.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    num_years = tensor.shape[-1]\n",
    "    for t in range(num_years - window):\n",
    "        X.append(tensor[..., t:t+window])\n",
    "        y.append(tensor[..., t+window])\n",
    "    return torch.stack(X), torch.stack(y)\n",
    "\n",
    "X, y = generar_secuencias(tensor_norm, window=5)\n",
    "print(\"Shape de X:\", X.shape)  # (n_samples, areas, productos, elementos, a√±os_ventana)\n",
    "print(\"Shape de y:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a149355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Sumamos NaN sobre elementos\n",
    "nan_per_year = torch.isnan(tensor).sum(dim=2)  # (√°reas, productos, a√±os)\n",
    "num_areas, num_prods, num_years = nan_per_year.shape\n",
    "\n",
    "# Convertimos a DataFrame largo\n",
    "data = []\n",
    "for a in range(num_areas):\n",
    "    for p in range(num_prods):\n",
    "        for y in range(num_years):\n",
    "            data.append({\n",
    "                \"√Årea\": a,\n",
    "                \"Producto\": p,\n",
    "                \"A√±o\": 1961 + y,  # ajusta si tu primer a√±o no es 1961\n",
    "                \"NaN_count\": int(nan_per_year[a,p,y])\n",
    "            })\n",
    "df_plot = pd.DataFrame(data)\n",
    "\n",
    "# Creamos el heatmap interactivo\n",
    "fig = px.density_heatmap(\n",
    "    df_plot,\n",
    "    x=\"Producto\",\n",
    "    y=\"√Årea\",\n",
    "    z=\"NaN_count\",\n",
    "    animation_frame=\"A√±o\",  # slider autom√°tico por a√±o\n",
    "    color_continuous_scale=\"Reds\",\n",
    "    labels={\"NaN_count\": \"Cantidad de NaN\"}\n",
    ")\n",
    "fig.update_layout(height=600, width=900, title_text=\"Valores faltantes por √Årea y Producto\")\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c779b70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
